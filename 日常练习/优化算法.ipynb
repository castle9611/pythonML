{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.773416Z",
     "start_time": "2020-12-14T08:28:21.413768Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3be59bf1a24c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import sys\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.781393Z",
     "start_time": "2020-12-14T08:28:21.410Z"
    }
   },
   "outputs": [],
   "source": [
    "def use_svg_display():\n",
    "# 用矢量图显示。\n",
    "    display.set_matplotlib_formats('svg')\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    use_svg_display()\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    # 设置图的尺寸\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "def train_2d(trainer, epioc=10):  \n",
    "    x1, x2, s1, s2 = -5, -2, 0, 0  # s1和s2是自变量状态，本章后续几节会使用\n",
    "    results = [(x1, x2)]\n",
    "    for i in range(epioc):\n",
    "        x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n",
    "        results.append((x1, x2))\n",
    "    print('epoch %d, x1 %f, x2 %f' % (i + 1, x1, x2))\n",
    "    return results\n",
    "\n",
    "def show_trace_2d(f, results):  \n",
    "    plt.plot(*zip(*results), '-o', color='#ff7f0e')\n",
    "    x1, x2 = np.meshgrid(np.arange(-5.5, 2.0, 0.1), np.arange(-3.0, 1.5, 0.1))\n",
    "    plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "\n",
    "def train_pytorch_ch7(optimizer_fn, optimizer_hyperparams, features, labels,\n",
    "                    batch_size=10, num_epochs=2):\n",
    "    # 初始化模型\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(features.shape[-1], 1)\n",
    "    )\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = optimizer_fn(net.parameters(), **optimizer_hyperparams)\n",
    "\n",
    "    def eval_loss():\n",
    "        return loss(net(features).view(-1), labels).item() / 2\n",
    "\n",
    "    ls = [eval_loss()]\n",
    "    data_iter = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(features, labels), batch_size, shuffle=True)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        start = time.time()\n",
    "        for batch_i, (X, y) in enumerate(data_iter):\n",
    "            # 除以2是为了和train_ch7保持一致, 因为squared_loss中除了2\n",
    "            l = loss(net(X).view(-1), y) / 2 \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_i + 1) * batch_size % 100 == 0:\n",
    "                ls.append(eval_loss())\n",
    "    # 打印结果和作图\n",
    "    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\n",
    "    set_figsize()\n",
    "    plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 局部最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.783390Z",
     "start_time": "2020-12-14T08:28:21.422Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * np.cos(np.pi * x)\n",
    "\n",
    "set_figsize((4.5, 2.5))\n",
    "x = np.arange(-1.0, 2.0, 0.1)\n",
    "fig,  = plt.plot(x, f(x))\n",
    "fig.axes.annotate('local minimum', xy=(-0.3, -0.25), xytext=(-0.77, -1.0),\n",
    "                  arrowprops=dict(arrowstyle='->'))\n",
    "fig.axes.annotate('global minimum', xy=(1.1, -0.95), xytext=(0.6, 0.8),\n",
    "                  arrowprops=dict(arrowstyle='->'))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 鞍点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.785383Z",
     "start_time": "2020-12-14T08:28:21.427Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-2.0, 2.0, 0.1)\n",
    "fig, = plt.plot(x, x**3)\n",
    "fig.axes.annotate('saddle point', xy=(0, -0.2), xytext=(-0.52, -5.0),\n",
    "                  arrowprops=dict(arrowstyle='->'))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.787377Z",
     "start_time": "2020-12-14T08:28:21.433Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-1: 1: 100j, -1: 1: 100j]\n",
    "z = x**2 - y**2\n",
    "\n",
    "ax = plt.figure(figsize=(8,6)).add_subplot(111, projection='3d')\n",
    "ax.plot_wireframe(x, y, z, **{'rstride': 4, 'cstride': 5})\n",
    "ax.plot([0], [0], [0], 'ro-')\n",
    "ticks = [-1,  0, 1]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "# ax.set_zticks(ticks)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降\n",
    "\n",
    "#### 一维梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.789372Z",
     "start_time": "2020-12-14T08:28:21.438Z"
    }
   },
   "outputs": [],
   "source": [
    "def gd(x, eta):\n",
    "    \n",
    "    results = [x]\n",
    "    for i in range(10):\n",
    "        x -= eta * 2 * x  # f(x) = x * x的导数为f'(x) = 2 * x\n",
    "        results.append(x)\n",
    "    print('epoch 10, x:', x)\n",
    "    return results\n",
    "\n",
    "res = gd(20, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.791367Z",
     "start_time": "2020-12-14T08:28:21.442Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_trace(res):\n",
    "    n = max(abs(min(res)), abs(max(res)), 10)\n",
    "    f_line = np.arange(-n, n, 0.1)\n",
    "    set_figsize()\n",
    "    plt.plot(f_line, [x * x for x in f_line])\n",
    "    plt.plot(res, [x * x for x in res], '-o')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "\n",
    "show_trace(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.793363Z",
     "start_time": "2020-12-14T08:28:21.450Z"
    }
   },
   "outputs": [],
   "source": [
    "show_trace(gd(20, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.795360Z",
     "start_time": "2020-12-14T08:28:21.455Z"
    }
   },
   "outputs": [],
   "source": [
    "show_trace(gd(20, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多维梯度下降\n",
    "多维函数$f(x) = x_1^2+2x_2^2$\n",
    "<br>梯度$\\nabla f(\\boldsymbol{x}) = [2x_1, 4x_2]^\\top$\n",
    "\n",
    "观察梯度下降从初始位置$[-5,-2]$开始对自变量$\\boldsymbol{x}$的迭代轨迹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.832272Z",
     "start_time": "2020-12-14T08:28:21.460Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-1: 1: 31j, -1: 1: 31j]\n",
    "z = x**2 + 2*y**2\n",
    "\n",
    "ax = plt.figure().add_subplot(111, projection='3d')\n",
    "ax.plot_wireframe(x, y, z, **{'rstride': 2, 'cstride': 2})\n",
    "ax.plot([0], [0], [0], 'rx')\n",
    "ticks = [-1,  0, 1]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks)\n",
    "ax.set_zticks(ticks)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.835251Z",
     "start_time": "2020-12-14T08:28:21.471Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_2d(x1, x2):  # 目标函数\n",
    "    return x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def gd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * 2 * x1, x2 - eta * 4 * x2, 0, 0)\n",
    "\n",
    "eta = 0.1 # 学习率为0.1\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(gd_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.837245Z",
     "start_time": "2020-12-14T08:28:21.478Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.4 # 学习率为0.4\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(gd_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.839240Z",
     "start_time": "2020-12-14T08:28:21.486Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.51\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(gd_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机梯度下降SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.841233Z",
     "start_time": "2020-12-14T08:28:21.492Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "\n",
    "def sgd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * (2 * x1 + np.random.normal(0)),\n",
    "            x2 - eta * (4 * x2 + np.random.normal(0)), 0, 0)\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(sgd_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小批量随机梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用NASA的测试不同飞机机翼噪音的数据集来比较各个优化算法。我们使用该数据集的前1,500个样本和5个特征，并使用标准化对数据进行预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.843228Z",
     "start_time": "2020-12-14T08:28:21.498Z"
    }
   },
   "outputs": [],
   "source": [
    "features, labels = d2l.get_data_ch7()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.845223Z",
     "start_time": "2020-12-14T08:28:21.502Z"
    }
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.848215Z",
     "start_time": "2020-12-14T08:28:21.509Z"
    }
   },
   "outputs": [],
   "source": [
    "# 梯度下降\n",
    "train_pytorch_ch7(optim.SGD, {\"lr\": 0.9}, features, labels, 1500, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.850210Z",
     "start_time": "2020-12-14T08:28:21.530Z"
    }
   },
   "outputs": [],
   "source": [
    "# 随机梯度下降\n",
    "train_pytorch_ch7(optim.SGD, {\"lr\": 0.005}, features, labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.852211Z",
     "start_time": "2020-12-14T08:28:21.546Z"
    }
   },
   "outputs": [],
   "source": [
    "# 小批量随机梯度下降  批量大小为10\n",
    "train_pytorch_ch7(optim.SGD, {\"lr\": 0.05}, features, labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降的问题\n",
    "\n",
    "$$f(\\boldsymbol{x})=0.1x_1^2+2x_2^2$$\n",
    "\n",
    "实现基于这个目标函数的梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.854199Z",
     "start_time": "2020-12-14T08:28:21.556Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.2 # 学习率\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def gd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * 0.2 * x1, x2 - eta * 4 * x2, 0, 0)\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(gd_2d, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.856195Z",
     "start_time": "2020-12-14T08:28:21.561Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.4 # 学习率\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def gd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * 0.2 * x1, x2 - eta * 4 * x2, 0, 0)\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(gd_2d, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.858188Z",
     "start_time": "2020-12-14T08:28:21.566Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.52\n",
    "show_trace_2d(f_2d, train_2d(gd_2d, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习率越过目标函数最优解后，竖直方向（$x_2$轴方向）逐渐发散"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标函数在竖直方向（$x_2$轴方向）比在水平方向（$x_1$轴方向）的斜率的绝对值更大<br>\n",
    "我们需要一个较小的学习率从而避免自变量在竖直方向上越过目标函数最优解。然而，这会造成自变量在水平方向上朝最优解移动变慢。\n",
    "<br><br>另一个看待问题的角度是，在纵轴上，你希望学习慢一点，因为你不想要这些摆动，但是在横轴上，你希望加快学习，你希望快速从左向右移，移向最小值，移向红点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动量法\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{v}_t &\\leftarrow \\gamma \\boldsymbol{v}_{t-1} + \\eta_t \\boldsymbol{g}_t, \\\\\n",
    "\\boldsymbol{x}_t &\\leftarrow \\boldsymbol{x}_{t-1} - \\boldsymbol{v}_t,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中，动量超参数$\\gamma$满足$0 \\leq \\gamma < 1$。当$\\gamma=0$时，动量法等价于小批量随机梯度下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.860183Z",
     "start_time": "2020-12-14T08:28:21.579Z"
    }
   },
   "outputs": [],
   "source": [
    "def momentum_2d(x1, x2, v1, v2):\n",
    "    v1 = gamma * v1 + eta * 0.2 * x1\n",
    "    v2 = gamma * v2 + eta * 4 * x2\n",
    "    return x1 - v1, x2 - v2, v1, v2\n",
    "\n",
    "eta, gamma = 0.4, 0.5\n",
    "show_trace_2d(f_2d, train_2d(momentum_2d, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.862178Z",
     "start_time": "2020-12-14T08:28:21.583Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用较大的学习率eta=0.6，自变量也不再发散\n",
    "eta = 0.25\n",
    "show_trace_2d(f_2d, train_2d(momentum_2d, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.864173Z",
     "start_time": "2020-12-14T08:28:21.589Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用较大的学习率eta=0.6，自变量也不再发散\n",
    "eta = 0.6\n",
    "show_trace_2d(f_2d, train_2d(momentum_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.867165Z",
     "start_time": "2020-12-14T08:28:21.594Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(torch.optim.SGD, {'lr': 0.02, 'momentum': 0.5},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.870156Z",
     "start_time": "2020-12-14T08:28:21.600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(torch.optim.SGD, {'lr': 0.02, 'momentum': 0.9},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.883123Z",
     "start_time": "2020-12-14T08:28:21.608Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(torch.optim.SGD, {'lr': 0.004, 'momentum': 0.9},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.891100Z",
     "start_time": "2020-12-14T08:28:21.625Z"
    }
   },
   "outputs": [],
   "source": [
    "def momentum_2d(x1, x2, v1, v2):\n",
    "    v1 = gamma * v1 + (1 - gamma) * 0.2 * (x1 - eta * gamma * v1)\n",
    "    v2 = gamma * v2 + (1 - gamma) * 4 * (x2 - eta * gamma *v2)\n",
    "    return x1 - eta * v1, x2 - eta * v2, v1, v2\n",
    "\n",
    "gamma, eta = 0.4, 0.5\n",
    "show_trace_2d(f_2d, train_2d(momentum_2d, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.894093Z",
     "start_time": "2020-12-14T08:28:21.642Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(torch.optim.SGD, {'lr': 0.02, 'momentum': 0.5, 'nesterov': True},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad\n",
    "$$\\boldsymbol{s}_t \\leftarrow \\boldsymbol{s}_{t-1} + \\boldsymbol{g}_t \\odot \\boldsymbol{g}_t,$$\n",
    "\n",
    "其中$\\odot$是按元素相乘。接着，我们将目标函数自变量中每个元素的学习率通过按元素运算重新调整一下：\n",
    "\n",
    "$$\\boldsymbol{x}_t \\leftarrow \\boldsymbol{x}_{t-1} - \\frac{\\eta}{\\sqrt{\\boldsymbol{s}_t + \\epsilon}} \\odot \\boldsymbol{g}_t,$$\n",
    "\n",
    "其中$\\eta$是学习率，$\\epsilon$是为了维持数值稳定性而添加的常数，如$10^{-6}$。这里开方、除法和乘法的运算都是按元素运算的。这些按元素运算使得目标函数自变量中每个元素都分别拥有自己的学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.896086Z",
     "start_time": "2020-12-14T08:28:21.666Z"
    }
   },
   "outputs": [],
   "source": [
    "def adagrad_2d(x1, x2, s1, s2):\n",
    "    g1, g2, eps = 0.2 * x1, 4 * x2, 1e-6  # 前两项为自变量梯度\n",
    "    s1 += g1 ** 2\n",
    "    s2 += g2 ** 2\n",
    "    x1 -= eta / math.sqrt(s1 + eps) * g1\n",
    "    x2 -= eta / math.sqrt(s2 + eps) * g2\n",
    "    return x1, x2, s1, s2\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "eta = 0.4\n",
    "show_trace_2d(f_2d, train_2d(adagrad_2d, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.899079Z",
     "start_time": "2020-12-14T08:28:21.688Z"
    }
   },
   "outputs": [],
   "source": [
    "eta = 1.5\n",
    "show_trace_2d(f_2d, train_2d(adagrad_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.903079Z",
     "start_time": "2020-12-14T08:28:21.694Z"
    }
   },
   "outputs": [],
   "source": [
    "# 简洁实现\n",
    "train_pytorch_ch7(torch.optim.Adagrad, {'lr': 0.1}, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "$$\\boldsymbol{s}_t \\leftarrow \\gamma \\boldsymbol{s}_{t-1} + (1 - \\gamma) \\boldsymbol{g}_t \\odot \\boldsymbol{g}_t$$\n",
    "$$\\boldsymbol{x}_t \\leftarrow \\boldsymbol{x}_{t-1} - \\frac{\\eta}{\\sqrt{\\boldsymbol{s}_t + \\epsilon}} \\odot \\boldsymbol{g}_t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.905065Z",
     "start_time": "2020-12-14T08:28:21.705Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmsprop_2d(x1, x2, s1, s2):\n",
    "    g1, g2, eps = 0.2 * x1, 4 * x2, 1e-6\n",
    "    s1 = gamma * s1 + (1 - gamma) * g1 ** 2\n",
    "    s2 = gamma * s2 + (1 - gamma) * g2 ** 2\n",
    "    x1 -= eta / math.sqrt(s1 + eps) * g1\n",
    "    x2 -= eta / math.sqrt(s2 + eps) * g2\n",
    "    return x1, x2, s1, s2\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "eta, gamma = 0.4, 0.9\n",
    "show_trace_2d(f_2d, train_2d(rmsprop_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.907058Z",
     "start_time": "2020-12-14T08:28:21.711Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(torch.optim.RMSprop, {'lr': 0.01, 'alpha': 0.9},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.908061Z",
     "start_time": "2020-12-14T08:28:21.727Z"
    }
   },
   "outputs": [],
   "source": [
    "def adam_2d(x1, x2, v1, v2, s1, s2):\n",
    "    g1, g2, eps = 0.2 * x1, 4 * x2, 1e-8\n",
    "    v1 = gamma_v * v1 + (1 - gamma_v) * g1\n",
    "    v2 = gamma_v * v2 + (1 - gamma_v) * g2\n",
    "    s1 = gamma_s * s1 + (1 - gamma_s) * g1 ** 2\n",
    "    s2 = gamma_s * s2 + (1 - gamma_s) * g2 ** 2\n",
    "    x1 -= eta * v1 / (math.sqrt(s1) + eps)\n",
    "    x2 -= eta * v2 / (math.sqrt(s2) + eps)\n",
    "    return x1, x2, v1, v2, s1, s2\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "eta, gamma_v, gamma_s = 0.1, 0.9, 0.999\n",
    "show_trace_2d(f_2d, train_adam_2d(adam_2d, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.911046Z",
     "start_time": "2020-12-14T08:28:21.742Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_adam_2d(trainer, epioc=10):\n",
    "    x1, x2, v1, v2, s1, s2 = -5, -2, 0, 0, 0, 0\n",
    "    results = [(x1, x2)]\n",
    "    for i in range(epioc):\n",
    "        x1, x2, v1, v2, s1, s2 = trainer(x1, x2, v1, v2, s1, s2)\n",
    "        results.append((x1, x2))\n",
    "    print('epoch %d, x1 %f, x2 %f' % (i + 1, x1, x2))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:28:22.913045Z",
     "start_time": "2020-12-14T08:28:21.747Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(torch.optim.Adam, {'lr': 0.01}, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
